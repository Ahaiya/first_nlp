2022-08-14 11:16:30,920 ----Preprocessing config parameters-----
2022-08-14 11:16:30,920 ---data_path = ./data/resume_data/
2022-08-14 11:16:30,920 ---split_ratio = 0.2
2022-08-14 11:16:30,920 ---random_state = 0
2022-08-14 11:16:30,920 ---embedding_col = 200
2022-08-14 11:16:30,920 ---max_len = 64
2022-08-14 11:16:30,920 ---convertor = ok
2022-08-14 11:16:30,920 Loading training data...
2022-08-14 11:17:20,344 Parsing original resume dataset...
2022-08-14 11:17:37,733 Splitting datasets, the splits ratio is 0.2, random state is 0
2022-08-14 11:17:37,749 Loading done.
2022-08-14 11:17:38,032 loading projection weights from /Users/soul/.text2vec/datasets/light_Tencent_AILab_ChineseEmbedding.bin
2022-08-14 11:17:39,525 KeyedVectors lifecycle event {'msg': 'loaded (143613, 200) matrix of type float32 from /Users/soul/.text2vec/datasets/light_Tencent_AILab_ChineseEmbedding.bin', 'binary': True, 'encoding': 'utf8', 'datetime': '2022-08-14T11:17:39.493043', 'gensim': '4.1.2', 'python': '3.9.12 (main, Apr  5 2022, 01:53:17) \n[Clang 12.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'load_word2vec_format'}
2022-08-14 11:17:42,651 Vecterizing data for neural network training...
2022-08-14 11:17:42,652 Creating vocabulary...
2022-08-14 11:17:42,786 Done. Got 57942 words
2022-08-14 11:17:42,787 Preparing data for training...
2022-08-14 11:17:44,511 Creating BiLSTM model...
2022-08-14 11:17:44,511 -------Training config parameters-------
2022-08-14 11:17:44,511 ---model_name = BiLSTM
2022-08-14 11:17:44,511 ---batch_size = 32
2022-08-14 11:17:44,512 ---dropout = 0.1
2022-08-14 11:17:44,512 ---embedding_col = 200
2022-08-14 11:17:44,512 ---max_len = 64
2022-08-14 11:17:44,512 ---optimizer = adam
2022-08-14 11:17:44,512 ---epochs = 1
2022-08-14 11:17:44,519 Found embedding matrix, setting trainable=false
2022-08-14 11:25:29,842 Accuracy : 0.6994176438183678
2022-08-14 11:25:29,842 
              precision    recall  f1-score   support

           0       0.85      0.56      0.67      1621
           1       0.73      0.64      0.68      1114
           2       0.73      0.49      0.58       656
           3       0.66      0.41      0.51      5272
           4       0.70      0.91      0.79     10354
           5       0.62      0.57      0.59       917
           6       0.74      0.23      0.35       721
           7       0.90      0.89      0.89      1465
           8       0.62      0.67      0.65      3294

   micro avg       0.70      0.70      0.70     25414
   macro avg       0.73      0.60      0.64     25414
weighted avg       0.70      0.70      0.68     25414
 samples avg       0.70      0.70      0.70     25414


